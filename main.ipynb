{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW Approach - Tracking + Pose Estimation with bbox on elbow and wrist keypoint estimation with persistent person id's and log if no people in frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "class ArmMovementTracker:\n",
    "    def __init__(self, movement_threshold=13, frame_memory=15):\n",
    "        self.trackers = {}\n",
    "        self.movement_threshold = movement_threshold\n",
    "        self.frame_memory = frame_memory\n",
    "\n",
    "    def get_tracker(self, person_id):\n",
    "        if person_id not in self.trackers:\n",
    "            self.trackers[person_id] = {\n",
    "                'prev_keypoints': {'left': {'wrist': None, 'elbow': None}, 'right': {'wrist': None, 'elbow': None}},\n",
    "                'movement_counter': {'left': 0, 'right': 0},\n",
    "                'active_action': None,\n",
    "                'keypoint_history': {'left': [], 'right': []},\n",
    "                'action_active': {'left': False, 'right': False}\n",
    "            }\n",
    "        return self.trackers[person_id]\n",
    "\n",
    "    def calculate_keypoint_movement(self, person_id, side, wrist_pos, elbow_pos, frame_count):\n",
    "        tracker = self.get_tracker(person_id)\n",
    "        prev_keypoints = tracker['prev_keypoints']\n",
    "        history = tracker['keypoint_history'][side]\n",
    "        \n",
    "        if frame_count % 3 == 0:\n",
    "            current_keypoints = {'wrist': wrist_pos, 'elbow': elbow_pos, 'frame': frame_count}\n",
    "            history.append(current_keypoints)\n",
    "            if len(history) > self.frame_memory:\n",
    "                history.pop(0)\n",
    "            prev_keypoints[side]['wrist'] = wrist_pos\n",
    "            prev_keypoints[side]['elbow'] = elbow_pos\n",
    "        return history\n",
    "\n",
    "    def check_significant_movement(self, history):\n",
    "        if len(history) < 2:\n",
    "            return False\n",
    "        total_movement = 0\n",
    "        for i in range(len(history) - 1):\n",
    "            curr = history[i]\n",
    "            next_frame = history[i + 1]\n",
    "            wrist_movement = np.sqrt((curr['wrist'][0] - next_frame['wrist'][0])**2 + (curr['wrist'][1] - next_frame['wrist'][1])**2)\n",
    "            elbow_movement = np.sqrt((curr['elbow'][0] - next_frame['elbow'][0])**2 + (curr['elbow'][1] - next_frame['elbow'][1])**2)\n",
    "            total_movement += (wrist_movement + elbow_movement) / 2\n",
    "        avg_movement = total_movement / (len(history) - 1)\n",
    "        return avg_movement > self.movement_threshold\n",
    "\n",
    "    def update_and_check_movement(self, person_id, side, wrist_pos, elbow_pos, frame_count):\n",
    "        tracker = self.get_tracker(person_id)\n",
    "        history = self.calculate_keypoint_movement(person_id, side, wrist_pos, elbow_pos, frame_count)\n",
    "        if frame_count % 3 == 0 and len(history) >= 2:\n",
    "            if self.check_significant_movement(history):\n",
    "                tracker['movement_counter'][side] += 1\n",
    "                if tracker['movement_counter'][side] >= self.frame_memory:\n",
    "                    tracker['action_active'][side] = True\n",
    "            else:\n",
    "                tracker['movement_counter'][side] = 0\n",
    "                tracker['action_active'][side] = False\n",
    "        return tracker['action_active'][side]\n",
    "\n",
    "def calculate_iou_rotated(points1, points2):\n",
    "    pts1 = np.array(points1, dtype=np.float32)\n",
    "    pts2 = np.array(points2, dtype=np.float32)\n",
    "    x_min = min(np.min(pts1[:, 0]), np.min(pts2[:, 0]))\n",
    "    y_min = min(np.min(pts1[:, 1]), np.min(pts2[:, 1]))\n",
    "    x_max = max(np.max(pts1[:, 0]), np.max(pts2[:, 0]))\n",
    "    y_max = max(np.max(pts1[:, 1]), np.max(pts2[:, 1]))\n",
    "    w = int((x_max - x_min) * frame_width)\n",
    "    h = int((y_max - y_min) * frame_height)\n",
    "    if w <= 0 or h <= 0:\n",
    "        return 0.0\n",
    "    mask1 = np.zeros((h, w), dtype=np.uint8)\n",
    "    mask2 = np.zeros((h, w), dtype=np.uint8)\n",
    "    pts1_mask = (pts1 - [x_min, y_min]) * [w, h]\n",
    "    pts2_mask = (pts2 - [x_min, y_min]) * [w, h]\n",
    "    cv2.fillPoly(mask1, [pts1_mask.astype(np.int32)], 1)\n",
    "    cv2.fillPoly(mask2, [pts2_mask.astype(np.int32)], 1)\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Load models\n",
    "tracker_model = YOLO(\"yolo11n.pt\")\n",
    "pose_model = YOLO(\"yolo11n-pose.pt\")\n",
    "video_path = \"TACO BELL demo 2.mp4\"\n",
    "\n",
    "# Video setup\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(\"output-1234.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "# Define pose connections\n",
    "skeleton = [(5, 7), (7, 9), (6, 8), (8, 10), (5, 6), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]\n",
    "\n",
    "# Initialize trackers and logs\n",
    "movement_tracker = ArmMovementTracker(movement_threshold=7, frame_memory=15)\n",
    "logging.basicConfig(filename=\"action_log.txt\", level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "# Load class labelsf\n",
    "with open('class.json', 'r') as f:\n",
    "    class_data = json.load(f)\n",
    "    categories = {cat['id']: cat['name'] for cat in class_data['categories']}\n",
    "\n",
    "# Load object coordinates\n",
    "boxes = []\n",
    "with open('cord.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = list(map(float, line.strip().split()))\n",
    "        class_id = int(values[0])\n",
    "        points = [(values[i], values[i + 1]) for i in range(1, len(values)-1, 2)]\n",
    "        xs = [p[0] for p in points]\n",
    "        ys = [p[1] for p in points]\n",
    "        x_center = sum(xs) / len(xs)\n",
    "        y_center = sum(ys) / len(ys)\n",
    "        width = max(xs) - min(xs)\n",
    "        height = max(ys) - min(ys)\n",
    "        boxes.append({\n",
    "            'class_id': class_id,\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'points': points,\n",
    "            'label': categories.get(class_id, f\"Class_{class_id}\")\n",
    "        })\n",
    "        print(f\"Loaded polygon: class_id={class_id}, points={points}\")\n",
    "\n",
    "# Process video\n",
    "frame_count = 0\n",
    "cv2.namedWindow(\"Pose Estimation with Action Detection\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "for track_result, pose_result in zip(tracker_model.track(video_path, stream=True, classes=[0], tracker=\"bytetrack.yaml\"),\n",
    "                                     pose_model(video_path, stream=True)):\n",
    "    frame_count += 1\n",
    "    frame = track_result.orig_img.copy()\n",
    "\n",
    "    # Tracking: Get bounding boxes and track_ids\n",
    "    tracked_people = {}\n",
    "    if track_result.boxes is not None and track_result.boxes.id is not None:\n",
    "        for box, track_id in zip(track_result.boxes.xyxy.cpu().numpy(), track_result.boxes.id.cpu().numpy()):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            center = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "            tracked_people[int(track_id)] = {'box': (x1, y1, x2, y2), 'center': center}\n",
    "        print(f\"Frame {frame_count}: Tracked {len(tracked_people)} people\")\n",
    "\n",
    "    # Draw tracked boxes\n",
    "    for track_id, data in tracked_people.items():\n",
    "        x1, y1, x2, y2 = data['box']\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    # Draw object polygons\n",
    "    for box in boxes:\n",
    "        points_abs = [(int(x * frame_width), int(y * frame_height)) for x, y in box['points']]\n",
    "        for i in range(len(points_abs)):\n",
    "            cv2.line(frame, points_abs[i], points_abs[(i + 1) % len(points_abs)], (0, 255, 0), 2)\n",
    "        cv2.putText(frame, box['label'], points_abs[0], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Pose: Match to tracked people and assign PIDs\n",
    "    if pose_result.keypoints is not None and len(pose_result.keypoints.data) > 0 and pose_result.keypoints.data.shape[1] > 0:\n",
    "\n",
    "        print(f\"Frame {frame_count}: Detected {len(pose_result.keypoints.data)} poses\")\n",
    "        poses = []\n",
    "        for keypoints in pose_result.keypoints.data.cpu().numpy():\n",
    "            valid_points = keypoints[keypoints[:, 2] > 0.5, :2]\n",
    "            if len(valid_points) > 0:\n",
    "                kp_center = np.mean(valid_points, axis=0)\n",
    "                poses.append({'keypoints': keypoints, 'center': (kp_center[0], kp_center[1])})\n",
    "\n",
    "        # Match poses to tracked people\n",
    "        matched_tracks = {}\n",
    "        used_track_ids = set()\n",
    "        for pose in poses:\n",
    "            min_dist = float('inf')\n",
    "            matched_track_id = None\n",
    "            for track_id, data in tracked_people.items():\n",
    "                if track_id in used_track_ids:\n",
    "                    continue\n",
    "                dist = np.sqrt((pose['center'][0] - data['center'][0])**2 + (pose['center'][1] - data['center'][1])**2)\n",
    "                if dist < min_dist and dist < 200:\n",
    "                    min_dist = dist\n",
    "                    matched_track_id = track_id\n",
    "            if matched_track_id is not None:\n",
    "                matched_tracks[matched_track_id] = pose\n",
    "                used_track_ids.add(matched_track_id)\n",
    "\n",
    "        # Assign PIDs and process actions\n",
    "        current_pids = {}\n",
    "        pid = 0\n",
    "        for track_id in sorted(matched_tracks.keys()):\n",
    "            if pid < len(tracked_people):\n",
    "                current_pids[pid] = {'track_id': track_id, 'pose': matched_tracks[track_id]}\n",
    "                keypoints = matched_tracks[track_id]['keypoints']\n",
    "                \n",
    "                # Draw keypoints and skeleton\n",
    "                for i, kp in enumerate(keypoints):\n",
    "                    if kp[2] > 0.5:\n",
    "                        x, y = int(kp[0]), int(kp[1])\n",
    "                        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "                        cv2.putText(frame, str(i), (x + 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "                for start_idx, end_idx in skeleton:\n",
    "                    if keypoints[start_idx][2] > 0.5 and keypoints[end_idx][2] > 0.5:\n",
    "                        start = (int(keypoints[start_idx][0]), int(keypoints[start_idx][1]))\n",
    "                        end = (int(keypoints[end_idx][0]), int(keypoints[end_idx][1]))\n",
    "                        cv2.line(frame, start, end, (0, 255, 255), 2)\n",
    "\n",
    "                # Label the tracking box\n",
    "                x1, y1, x2, y2 = tracked_people[track_id]['box']\n",
    "                cv2.putText(frame, f\"P{pid}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Action detection\n",
    "                body_part_boxes = []\n",
    "                for arm_side, wrist_idx, elbow_idx in [('left', 9, 7), ('right', 10, 8)]:\n",
    "                    if keypoints[wrist_idx][2] > 0.65 and keypoints[elbow_idx][2] > 0.65:\n",
    "                        wrist = keypoints[wrist_idx][:2]\n",
    "                        elbow = keypoints[elbow_idx][:2]\n",
    "                        is_action_active = movement_tracker.update_and_check_movement(pid, arm_side, wrist, elbow, frame_count)\n",
    "                        color = (0, 255, 0) if is_action_active else (0, 0, 255)\n",
    "                        cv2.line(frame, (int(wrist[0]), int(wrist[1])), (int(elbow[0]), int(elbow[1])), color, 2)\n",
    "\n",
    "                        min_x = max(0, min(wrist[0], elbow[0]) - 20)\n",
    "                        min_y = max(0, min(wrist[1], elbow[1]) - 20)\n",
    "                        max_x = min(frame_width, max(wrist[0], elbow[0]) + 20)\n",
    "                        max_y = min(frame_height, max(wrist[1], elbow[1]) + 20)\n",
    "                        arm_points = [\n",
    "                            (min_x / frame_width, min_y / frame_height),\n",
    "                            (max_x / frame_width, min_y / frame_height),\n",
    "                            (max_x / frame_width, max_y / frame_height),\n",
    "                            (min_x / frame_width, max_y / frame_height)\n",
    "                        ]\n",
    "                        body_part_boxes.append({\n",
    "                            \"box\": [min_x, min_y, max_x, max_y],\n",
    "                            \"points\": arm_points,\n",
    "                            \"name\": f\"P{pid}_{arm_side}_arm\",\n",
    "                            \"hand\": arm_side,\n",
    "                            \"person_id\": pid\n",
    "                        })\n",
    "                        cv2.rectangle(frame, (int(min_x), int(min_y)), (int(max_x), int(max_y)), color, 2)\n",
    "\n",
    "                # Check interactions with objects\n",
    "                person_interactions = defaultdict(set)\n",
    "                for box in boxes:\n",
    "                    for body_part in body_part_boxes:\n",
    "                        if keypoints[body_part['hand'] == 'left' and 9 or 10][2] > 0.5:\n",
    "                            iou = calculate_iou_rotated(body_part[\"points\"], box['points'])\n",
    "                            if iou > 0.05:\n",
    "                                person_id = body_part['person_id']\n",
    "                                arm_side = body_part['hand']\n",
    "                                tracker = movement_tracker.get_tracker(person_id)\n",
    "                                if tracker['action_active'][arm_side]:\n",
    "                                    person_interactions[person_id].add(box['label'])\n",
    "\n",
    "                for person_id, interacted_objects in person_interactions.items():\n",
    "                    for obj_label in interacted_objects:\n",
    "                        action = f\"P{person_id} working with {obj_label}\"\n",
    "                        for box in boxes:\n",
    "                            if box['label'] == obj_label:\n",
    "                                points_abs = [(int(x * frame_width), int(y * frame_height)) for x, y in box['points']]\n",
    "                                action_x, action_y = points_abs[0][0], points_abs[0][1] + 20\n",
    "                                cv2.putText(frame, action, (action_x, action_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "                                logging.info(f\"Frame {frame_count}: {action}, {len(tracked_people)} people\")\n",
    "\n",
    "                pid += 1\n",
    "\n",
    "    else:\n",
    "        print(f\"Frame {frame_count}: No poses detected\")\n",
    "        logging.info(f\"Frame {frame_count}: No action detected, 0 people\")\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Pose Estimation with Action Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Cleanup\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Timestamp  Number of Unique People               Actions\n",
      "0    00:00:21                        1  [No action detected]\n",
      "1    00:00:26                        1  [No action detected]\n",
      "2    00:00:27                        1  [No action detected]\n",
      "3    00:00:28                        1  [No action detected]\n",
      "4    00:00:29                        1  [No action detected]\n",
      "..        ...                      ...                   ...\n",
      "190  00:04:43                        1  [No action detected]\n",
      "191  00:04:44                        1  [No action detected]\n",
      "192  00:04:45                        0  [No action detected]\n",
      "193  00:04:46                        0  [No action detected]\n",
      "194  00:04:48                        2  [No action detected]\n",
      "\n",
      "[195 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('action_log.txt', 'r') as f:\n",
    "    log_lines = f.readlines()\n",
    "\n",
    "parsed_data = []\n",
    "for line in log_lines:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        parts = line.split(\": \", 1)\n",
    "        frame_part = parts[0]\n",
    "        rest = parts[1]\n",
    "        \n",
    "        frame_num = int(frame_part.split(\"Frame \")[1])\n",
    "        \n",
    "        # Handle both action and no-action cases\n",
    "        if \"No action detected\" in rest:\n",
    "            num_people = int(rest.split(\", \")[1].split()[0])\n",
    "            person_id = \"None\"\n",
    "            station = \"None\"\n",
    "        else:\n",
    "            action_text, people_text = rest.split(\", \", 1)\n",
    "            num_people = int(people_text.split()[0])\n",
    "            person_id = action_text.split(\" working with \")[0]\n",
    "            station = action_text.split(\" working with \")[1]\n",
    "        \n",
    "        # Calculate timestamp\n",
    "        total_seconds = frame_num // 10\n",
    "        hours = total_seconds // 3600\n",
    "        minutes = (total_seconds % 3600) // 60\n",
    "        seconds = total_seconds % 60\n",
    "        timestamp = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        \n",
    "        parsed_data.append({\n",
    "            \"Frame\": frame_num,\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"Person\": person_id,\n",
    "            \"Station\": station,\n",
    "            \"NumPeople\": num_people\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(parsed_data)\n",
    "\n",
    "# Group actions by timestamp and person\n",
    "grouped_actions = df.groupby(['Timestamp', 'Person'])['Station'].apply(lambda x: '/'.join(sorted(set(x)))).reset_index()\n",
    "grouped_actions['Action'] = grouped_actions.apply(\n",
    "    lambda row: f\"{row['Person']} working with {row['Station']}\" if row['Person'] != \"None\" else \"No action detected\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Aggregate by timestamp\n",
    "result = df.groupby('Timestamp').agg({\n",
    "    'NumPeople': 'max',\n",
    "}).reset_index()\n",
    "\n",
    "actions_by_timestamp = grouped_actions.groupby('Timestamp')['Action'].apply(list).reset_index()\n",
    "result = result.merge(actions_by_timestamp, on='Timestamp')\n",
    "\n",
    "# Format result\n",
    "result.columns = ['Timestamp', 'Number of Unique People', 'Actions']\n",
    "result['Timestamp'] = pd.to_timedelta(result['Timestamp'])\n",
    "result = result.sort_values('Timestamp')\n",
    "result['Timestamp'] = result['Timestamp'].apply(lambda x: f\"{x.components.hours:02d}:{x.components.minutes:02d}:{x.components.seconds:02d}\")\n",
    "\n",
    "print(result)\n",
    "result.to_csv('action_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
